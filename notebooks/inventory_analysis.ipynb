{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retail Inventory Health Analysis\n",
    "\n",
    "**Client:** Distressed Retail Client  \n",
    "**Objective:** Reconcile three inventory data sources, identify actionable insights, and build a reusable analysis framework.\n",
    "\n",
    "## Data Sources\n",
    "| Source | Format | Description |\n",
    "|--------|--------|-------------|\n",
    "| POS System | CSV | 500K+ transactions with messy data |\n",
    "| Inventory Mgmt | Excel | 265 products with manual overrides |\n",
    "| E-commerce | JSON | 125K orders with different ID scheme |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add src to path\n",
    "sys.path.insert(0, str(Path.cwd().parent / \"src\"))\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables (for OpenAI API key)\n",
    "load_dotenv()\n",
    "\n",
    "# Display settings\n",
    "pd.set_option('display.max_columns', 20)\n",
    "pd.set_option('display.max_rows', 50)\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "\n",
    "DATA_DIR = Path.cwd().parent / \"data\" / \"raw\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Loading & Cleaning\n",
    "\n",
    "Using the client-specific loader that handles:\n",
    "- Multiple date formats in POS data\n",
    "- SKU normalization across systems\n",
    "- Notes column parsing for inventory overrides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from clients.retail_client import RetailClientLoader\n",
    "\n",
    "loader = RetailClientLoader(DATA_DIR)\n",
    "data = loader.load_all()\n",
    "\n",
    "pos = data.pos_transactions\n",
    "inv = data.inventory\n",
    "ecom = data.ecommerce_orders\n",
    "\n",
    "print(f\"POS Transactions: {len(pos):,} rows\")\n",
    "print(f\"Inventory Items: {len(inv):,} rows\")\n",
    "print(f\"E-commerce Orders: {len(ecom):,} rows\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Quality Assessment\n",
    "\n",
    "Automated quality checks ran during loading. Let's review the findings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quality summary\n",
    "for source, report in data.quality_reports.items():\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"{report.source_name}: {report.total_rows:,} rows\")\n",
    "    print(f\"Critical issues: {len(report.critical_issues)}\")\n",
    "    print(f\"Warnings: {len(report.warning_issues)}\")\n",
    "    \n",
    "    for issue in report.issues[:5]:  # Show top 5\n",
    "        print(f\"  - [{issue.severity.upper()}] {issue.column}: {issue.description}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### POS Data Issues\n",
    "\n",
    "The POS system has significant data quality issues that the client should address:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Date format distribution (the messiness)\n",
    "print(\"Sample of date formats found:\")\n",
    "print(pos['date'].head(20).tolist())\n",
    "\n",
    "# Payment method inconsistencies\n",
    "print(\"\\nPayment method values (before cleaning):\")\n",
    "print(pos['payment_method'].value_counts())\n",
    "\n",
    "# Missing data\n",
    "print(\"\\nMissing values:\")\n",
    "print(pos.isnull().sum()[pos.isnull().sum() > 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inventory Notes - Manual Overrides\n",
    "\n",
    "The ops team uses the Notes column to track corrections. This is a workaround for system issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show items with manual overrides\n",
    "overrides = inv[inv['notes'].notna()][['item_code', 'description', 'qty_on_hand', 'physical_count_override', 'adjustment', 'notes']]\n",
    "print(f\"Items with notes: {len(overrides)}\")\n",
    "print(f\"Items with physical count corrections: {inv['physical_count_override'].notna().sum()}\")\n",
    "print(f\"Items with adjustments: {inv['adjustment'].notna().sum()}\")\n",
    "\n",
    "overrides.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Product Matching Across Systems\n",
    "\n",
    "The three systems use different product identifiers:\n",
    "- **POS:** Various SKU formats (SKU-XXXX, XXXX, XXXXA)\n",
    "- **Inventory:** Numeric Item Codes\n",
    "- **E-commerce:** ECOM-XXXXXX format\n",
    "\n",
    "We'll match by normalized product name since IDs don't align."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate POS sales by normalized SKU\n",
    "pos_sales = pos[pos['quantity'] > 0].copy()\n",
    "pos_returns = pos[pos['quantity'] < 0].copy()\n",
    "\n",
    "pos_by_sku = pos_sales.groupby('sku_normalized').agg(\n",
    "    total_sold=('quantity', 'sum'),\n",
    "    revenue=('line_total', 'sum'),\n",
    "    transactions=('transaction_id', 'count'),\n",
    "    product_name=('product_name', 'first'),\n",
    "    last_sale=('date_parsed', 'max')\n",
    ").reset_index()\n",
    "\n",
    "# Add returns\n",
    "returns_by_sku = pos_returns.groupby('sku_normalized')['quantity'].sum().abs().reset_index()\n",
    "returns_by_sku.columns = ['sku_normalized', 'return_units']\n",
    "pos_by_sku = pos_by_sku.merge(returns_by_sku, on='sku_normalized', how='left')\n",
    "pos_by_sku['return_units'] = pos_by_sku['return_units'].fillna(0)\n",
    "\n",
    "print(f\"Unique products in POS: {len(pos_by_sku)}\")\n",
    "pos_by_sku.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Match POS to Inventory by normalized product name\n",
    "from core.parsers import ProductNameNormalizer\n",
    "\n",
    "normalizer = ProductNameNormalizer()\n",
    "\n",
    "# Create lookup from inventory\n",
    "inv_lookup = inv.set_index('description_normalized')[['item_code_normalized', 'qty_adjusted', 'reorder_level', 'retail_price', 'category', 'location']].to_dict('index')\n",
    "\n",
    "# Match POS products to inventory\n",
    "pos_by_sku['product_name_normalized'] = normalizer.normalize_series(pos_by_sku['product_name'])\n",
    "pos_by_sku['inv_match'] = pos_by_sku['product_name_normalized'].map(\n",
    "    lambda x: inv_lookup.get(x) if x in inv_lookup else None\n",
    ")\n",
    "\n",
    "matched = pos_by_sku[pos_by_sku['inv_match'].notna()]\n",
    "unmatched = pos_by_sku[pos_by_sku['inv_match'].isna()]\n",
    "\n",
    "print(f\"Matched to inventory: {len(matched)} ({len(matched)/len(pos_by_sku)*100:.1f}%)\")\n",
    "print(f\"Unmatched: {len(unmatched)} ({len(unmatched)/len(pos_by_sku)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Inventory Health Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Stockout Risk\n",
    "\n",
    "Products likely to run out based on current stock vs. sales velocity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from core.analysis import compute_sales_velocity, identify_stockout_risks\n",
    "\n",
    "# Compute sales velocity\n",
    "velocity = compute_sales_velocity(pos, sku_col='sku_normalized', qty_col='quantity', date_col='date_parsed')\n",
    "\n",
    "# Identify stockout risks\n",
    "stockout_risks = identify_stockout_risks(\n",
    "    inv, velocity,\n",
    "    inv_sku_col='item_code_normalized',\n",
    "    inv_qty_col='qty_adjusted',\n",
    "    vel_sku_col='sku_normalized'\n",
    ")\n",
    "\n",
    "print(f\"Products at stockout risk: {len(stockout_risks)}\")\n",
    "print(f\"  - Critical (‚â§7 days): {len(stockout_risks[stockout_risks['risk_level']=='critical'])}\")\n",
    "print(f\"  - High (‚â§14 days): {len(stockout_risks[stockout_risks['risk_level']=='high'])}\")\n",
    "print(f\"  - Medium (‚â§30 days): {len(stockout_risks[stockout_risks['risk_level']=='medium'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top stockout risks\n",
    "stockout_display = stockout_risks[['item_code', 'description', 'qty_adjusted', 'avg_daily_sales', 'days_of_stock', 'risk_level', 'category']].head(15)\n",
    "stockout_display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Dead Inventory\n",
    "\n",
    "Products not moving that tie up capital."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from core.analysis import identify_dead_inventory\n",
    "\n",
    "dead_inv = identify_dead_inventory(\n",
    "    inv, pos,\n",
    "    inv_sku_col='item_code_normalized',\n",
    "    inv_qty_col='qty_adjusted',\n",
    "    inv_price_col='retail_price',\n",
    "    txn_sku_col='sku_normalized',\n",
    "    txn_date_col='date_parsed',\n",
    "    dead_days_threshold=60\n",
    ")\n",
    "\n",
    "print(f\"Dead inventory items (no sales in 60+ days): {len(dead_inv)}\")\n",
    "print(f\"Total value at risk: ${dead_inv['value_at_risk'].sum():,.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top dead inventory by value\n",
    "dead_display = dead_inv[['item_code', 'description', 'qty_adjusted', 'retail_price', 'days_since_last_sale', 'value_at_risk', 'category']].head(15)\n",
    "dead_display"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Channel Comparison (In-Store vs Online)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from core.analysis import compute_channel_comparison\n",
    "\n",
    "channel_data = compute_channel_comparison(pos, ecom)\n",
    "\n",
    "print(\"Channel Comparison:\")\n",
    "print(\"=\"*50)\n",
    "print(f\"{'Metric':<30} {'In-Store':>12} {'Online':>12}\")\n",
    "print(\"-\"*50)\n",
    "print(f\"{'Revenue':.<30} ${channel_data['in_store']['total_revenue']:>10,.0f} ${channel_data['online']['total_revenue']:>10,.0f}\")\n",
    "print(f\"{'Units Sold':.<30} {channel_data['in_store']['total_units']:>12,} {channel_data['online']['total_units']:>12,}\")\n",
    "print(f\"{'Transactions':.<30} {channel_data['in_store']['transaction_count']:>12,} {channel_data['online']['transaction_count']:>12,}\")\n",
    "print(f\"{'Avg Order Value':.<30} ${channel_data['in_store']['avg_order_value']:>10,.2f} ${channel_data['online']['avg_order_value']:>10,.2f}\")\n",
    "print(f\"{'Return Rate':.<30} {channel_data['in_store']['return_rate']*100:>11.1f}% {channel_data['online']['return_rate']*100:>11.1f}%\")\n",
    "print(\"=\"*50)\n",
    "print(f\"In-store share of revenue: {channel_data['comparison']['revenue_split_instore_pct']:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize channel comparison\n",
    "fig, axes = plt.subplots(1, 3, figsize=(14, 4))\n",
    "\n",
    "# Revenue split\n",
    "axes[0].pie(\n",
    "    [channel_data['in_store']['total_revenue'], channel_data['online']['total_revenue']],\n",
    "    labels=['In-Store', 'Online'],\n",
    "    autopct='%1.1f%%',\n",
    "    colors=['#2ecc71', '#3498db']\n",
    ")\n",
    "axes[0].set_title('Revenue Split')\n",
    "\n",
    "# AOV comparison\n",
    "channels = ['In-Store', 'Online']\n",
    "aovs = [channel_data['in_store']['avg_order_value'], channel_data['online']['avg_order_value']]\n",
    "axes[1].bar(channels, aovs, color=['#2ecc71', '#3498db'])\n",
    "axes[1].set_ylabel('Average Order Value ($)')\n",
    "axes[1].set_title('AOV Comparison')\n",
    "\n",
    "# Return rates\n",
    "return_rates = [channel_data['in_store']['return_rate']*100, channel_data['online']['return_rate']*100]\n",
    "axes[2].bar(channels, return_rates, color=['#2ecc71', '#3498db'])\n",
    "axes[2].set_ylabel('Return Rate (%)')\n",
    "axes[2].set_title('Return Rate Comparison')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../outputs/channel_comparison.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Items Below Reorder Level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "below_reorder = inv[inv['below_reorder_level']].sort_values('qty_adjusted')\n",
    "print(f\"Items below reorder level: {len(below_reorder)}\")\n",
    "\n",
    "below_reorder[['item_code', 'description', 'qty_adjusted', 'reorder_level', 'category', 'location']].head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Key Metrics Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from core.analysis import compute_key_metrics\n",
    "\n",
    "key_metrics = compute_key_metrics(inv, pos, ecom, stockout_risks, dead_inv)\n",
    "\n",
    "print(\"Key Metrics:\")\n",
    "print(\"=\"*50)\n",
    "for k, v in key_metrics.items():\n",
    "    if isinstance(v, float) and v > 1000:\n",
    "        print(f\"{k}: ${v:,.2f}\" if 'value' in k or 'revenue' in k else f\"{k}: {v:,.2f}\")\n",
    "    elif isinstance(v, float):\n",
    "        print(f\"{k}: {v:.2f}\")\n",
    "    else:\n",
    "        print(f\"{k}: {v:,}\" if isinstance(v, int) else f\"{k}: {v}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. AI-Assisted Insight Generation\n",
    "\n",
    "Using GPT-4 with structured outputs (Pydantic) to generate insights and recommendations.\n",
    "\n",
    "**What the AI does well:**\n",
    "- Synthesizing patterns across data points\n",
    "- Generating natural language explanations\n",
    "- Prioritizing recommendations\n",
    "\n",
    "**What I verified/corrected:**\n",
    "- All numeric values are computed programmatically, not by the LLM\n",
    "- Rankings are cross-checked against the data\n",
    "- Specific SKUs and product names are passed to the LLM, not generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Check if API key is available\n",
    "if not os.getenv('OPENAI_API_KEY'):\n",
    "    print(\"‚ö†Ô∏è  OPENAI_API_KEY not set. Skipping AI insight generation.\")\n",
    "    print(\"   Set it in .env file to enable AI-generated insights.\")\n",
    "    ai_enabled = False\n",
    "else:\n",
    "    ai_enabled = True\n",
    "    print(\"‚úì OpenAI API key found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ai_enabled:\n",
    "    from core.insights import InsightGenerator\n",
    "    \n",
    "    # Prepare data for AI\n",
    "    stockout_data = stockout_risks[['item_code', 'description', 'qty_adjusted', 'days_of_stock', 'risk_level', 'category']].head(20).to_dict('records')\n",
    "    dead_inv_data = dead_inv[['item_code', 'description', 'qty_adjusted', 'days_since_last_sale', 'value_at_risk', 'category']].head(20).to_dict('records')\n",
    "    \n",
    "    quality_issues = []\n",
    "    for source, report in data.quality_reports.items():\n",
    "        for issue in report.issues:\n",
    "            quality_issues.append({\n",
    "                'source': source,\n",
    "                'column': issue.column,\n",
    "                'issue': issue.issue_type,\n",
    "                'severity': issue.severity,\n",
    "                'count': issue.count\n",
    "            })\n",
    "    \n",
    "    # Empty reconciliation for now (would need more complex logic for full implementation)\n",
    "    reconciliation_data = []\n",
    "    \n",
    "    # Generate insights\n",
    "    generator = InsightGenerator(model=\"gpt-4o-mini\")\n",
    "    \n",
    "    try:\n",
    "        report = generator.generate_insights(\n",
    "            stockout_data=stockout_data,\n",
    "            dead_inventory_data=dead_inv_data,\n",
    "            reconciliation_data=reconciliation_data,\n",
    "            channel_data=channel_data,\n",
    "            quality_issues=quality_issues,\n",
    "            key_metrics=key_metrics\n",
    "        )\n",
    "        \n",
    "        print(\"AI-Generated Executive Summary:\")\n",
    "        print(\"=\"*60)\n",
    "        print(report.executive_summary)\n",
    "    except Exception as e:\n",
    "        print(f\"Error generating AI insights: {e}\")\n",
    "        report = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if ai_enabled and report:\n",
    "    print(\"\\nAI-Generated Recommendations:\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    print(\"\\nüì¶ Stockout Risks:\")\n",
    "    for risk in report.stockout_risks[:5]:\n",
    "        print(f\"  [{risk.risk_level.upper()}] {risk.product_name}: {risk.days_of_stock:.0f} days of stock\")\n",
    "        print(f\"    ‚Üí {risk.recommendation}\")\n",
    "    \n",
    "    print(\"\\nüèöÔ∏è Dead Inventory:\")\n",
    "    for dead in report.dead_inventory[:5]:\n",
    "        print(f\"  {dead.product_name}: ${dead.estimated_value:,.0f} value, {dead.days_since_last_sale} days\")\n",
    "        print(f\"    ‚Üí {dead.recommendation}\")\n",
    "    \n",
    "    print(\"\\nüîß Data Quality Fixes:\")\n",
    "    for rec in report.data_quality_recommendations[:5]:\n",
    "        print(f\"  [{rec.priority.upper()}] {rec.system}: {rec.issue}\")\n",
    "        print(f\"    Impact: {rec.business_impact}\")\n",
    "        print(f\"    Fix: {rec.fix_recommendation}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Data Quality Recommendations for Client\n",
    "\n",
    "Based on our analysis, here are the issues the client should fix in their source systems:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Data Quality Issues to Address:\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\\n1. POS SYSTEM\")\n",
    "print(\"-\" * 40)\n",
    "print(\"‚Ä¢ Date formats: 4+ different formats across transactions\")\n",
    "print(\"  ‚Üí Standardize on ISO format (YYYY-MM-DD)\")\n",
    "print(f\"‚Ä¢ Missing store_id: {pos['store_id'].isna().sum():,} transactions ({pos['store_id'].isna().sum()/len(pos)*100:.1f}%)\")\n",
    "print(\"  ‚Üí Require store_id at point of sale\")\n",
    "print(f\"‚Ä¢ Missing customer_id: {pos['customer_id'].isna().sum():,} transactions\")\n",
    "print(\"  ‚Üí Expected for cash sales, but review card transactions\")\n",
    "print(\"‚Ä¢ Payment method inconsistency: 'CASH' vs 'Cash' vs 'cash'\")\n",
    "print(\"  ‚Üí Enforce dropdown selection instead of free text\")\n",
    "print(\"‚Ä¢ TEST/VOID transactions in production data\")\n",
    "print(\"  ‚Üí Filter these at export or use separate test environment\")\n",
    "\n",
    "print(\"\\n2. INVENTORY SYSTEM\")\n",
    "print(\"-\" * 40)\n",
    "print(f\"‚Ä¢ {inv['physical_count_override'].notna().sum()} items have manual count corrections\")\n",
    "print(\"  ‚Üí Investigate why system counts are wrong\")\n",
    "print(\"  ‚Üí Consider more frequent cycle counts\")\n",
    "print(f\"‚Ä¢ {inv['adjustment'].notna().sum()} items have manual adjustments\")\n",
    "print(\"  ‚Üí These should flow through the system, not notes\")\n",
    "\n",
    "print(\"\\n3. CROSS-SYSTEM\")\n",
    "print(\"-\" * 40)\n",
    "print(\"‚Ä¢ No common product identifier across POS, Inventory, and E-commerce\")\n",
    "print(\"  ‚Üí Implement a master product ID that all systems share\")\n",
    "print(\"‚Ä¢ SKU formats vary: 'SKU-12345', '12345', '012345'\")\n",
    "print(\"  ‚Üí Standardize SKU format with validation rules\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Save Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = Path.cwd().parent / \"outputs\"\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# Save stockout risks\n",
    "stockout_risks[['item_code', 'description', 'qty_adjusted', 'avg_daily_sales', 'days_of_stock', 'risk_level', 'category', 'reorder_level']].to_csv(\n",
    "    output_dir / 'stockout_risks.csv', index=False\n",
    ")\n",
    "\n",
    "# Save dead inventory\n",
    "dead_inv[['item_code', 'description', 'qty_adjusted', 'retail_price', 'days_since_last_sale', 'value_at_risk', 'category']].to_csv(\n",
    "    output_dir / 'dead_inventory.csv', index=False\n",
    ")\n",
    "\n",
    "# Save below reorder\n",
    "below_reorder[['item_code', 'description', 'qty_adjusted', 'reorder_level', 'category', 'location']].to_csv(\n",
    "    output_dir / 'below_reorder_level.csv', index=False\n",
    ")\n",
    "\n",
    "# Save key metrics\n",
    "import json\n",
    "with open(output_dir / 'key_metrics.json', 'w') as f:\n",
    "    json.dump(key_metrics, f, indent=2)\n",
    "\n",
    "print(f\"Outputs saved to {output_dir}\")\n",
    "print(\"Files created:\")\n",
    "for f in output_dir.glob('*'):\n",
    "    print(f\"  - {f.name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary of Findings\n",
    "\n",
    "### Immediate Actions Required\n",
    "\n",
    "1. **Reorder urgently**: Several items are critically low on stock (< 7 days supply)\n",
    "2. **Review dead inventory**: Significant capital tied up in non-moving stock\n",
    "3. **Fix POS date formats**: Data quality issue that makes analysis harder\n",
    "\n",
    "### System Improvements Needed\n",
    "\n",
    "1. Implement unified product ID across all systems\n",
    "2. Move inventory adjustments from Notes to proper system fields\n",
    "3. Standardize POS data entry (dates, payment methods)\n",
    "\n",
    "### What's Reusable for Next Client\n",
    "\n",
    "- `src/core/parsers.py`: Date and SKU parsers handle common retail formats\n",
    "- `src/core/quality.py`: Data quality framework works with any pandas DataFrame\n",
    "- `src/core/analysis.py`: Sales velocity, stockout risk, dead inventory logic\n",
    "- `src/core/insights.py`: AI insight generator with Pydantic models\n",
    "\n",
    "### What's Client-Specific\n",
    "\n",
    "- `src/clients/retail_client.py`: Specific column mappings, Notes parsing patterns"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
